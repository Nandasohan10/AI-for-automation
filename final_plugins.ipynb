{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_cognito_access_token(client_id, client_secret, token_url):\n",
    "    # Prepare the data for the token request\n",
    "    data = {\n",
    "        'grant_type': 'client_credentials',\n",
    "    }\n",
    "\n",
    "    # Make the POST request to get the token\n",
    "    response = requests.post(token_url, data=data, auth=(client_id, client_secret))\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON response\n",
    "        token_info = response.json()\n",
    "        return token_info['access_token']\n",
    "    else:\n",
    "        # Handle error\n",
    "        raise Exception(f\"Failed to get token: {response.status_code} - {response.text}\")\n",
    "\n",
    "# Replace these with your Cognito App Client ID and Secret\n",
    "client_id = '1m2f2ib1qatacreojll4aommfo'\n",
    "client_secret = 'o30f697g1s7fm9jrrlveeiu4tok3aulpie90709g86gijvccc2n'\n",
    "\n",
    "# Replace this with your Cognito token endpoint (Stg or Prod)\n",
    "token_url = 'https://logiai-stg.auth.us-west-2.amazoncognito.com/oauth2/token'\n",
    "\n",
    "access_token = get_cognito_access_token(client_id, client_secret, token_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction the required html elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured extracted elements saved to: icons.html\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup, Comment\n",
    "import os\n",
    "\n",
    "\n",
    "input_html_path = 'raw_plugines.html'\n",
    "output_html_path = 'plugines.html'\n",
    "\n",
    "def extract_important_elements(input_html_path, output_html_path):\n",
    "    with open(input_html_path, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Extract key interactive elements\n",
    "    elements = []\n",
    "    selectors = ['input', 'button', 'select', 'textarea', 'a']\n",
    "    for selector in selectors:\n",
    "        elements += soup.find_all(selector)\n",
    "\n",
    "    # Add custom class-based elements\n",
    "    elements += soup.find_all(class_='test-element')\n",
    "\n",
    "    # Create a clean, structured soup for output\n",
    "    structured_soup = BeautifulSoup('<html><head><title>Extracted Elements</title></head><body></body></html>', 'html.parser')\n",
    "    body = structured_soup.body\n",
    "\n",
    "    # Add a header for organization\n",
    "    body.append(structured_soup.new_tag(\"h1\"))\n",
    "    body.h1.string = \"Extracted Important Elements for Testing\"\n",
    "\n",
    "    for idx, el in enumerate(elements):\n",
    "        wrapper = structured_soup.new_tag(\"div\")\n",
    "        wrapper['class'] = 'extracted-element'\n",
    "        comment = structured_soup.new_string(f' Element #{idx + 1}: <{el.name}> ', Comment)\n",
    "        body.append(comment)\n",
    "        wrapper.append(el)\n",
    "        body.append(wrapper)\n",
    "\n",
    "    with open(output_html_path, 'w', encoding='utf-8') as output_file:\n",
    "        output_file.write(structured_soup.prettify())\n",
    "\n",
    "    print(f\"Structured extracted elements saved to: {output_html_path}\")\n",
    "\n",
    "# Run the function\n",
    "extract_important_elements(input_html_path, output_html_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing the huge html into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Folder 'chunks_for_testing' created.\n",
      "✅ Chunk 1 saved to: chunks_for_testing\\beta-marketPlace_for_testing_chunk_1.html\n",
      "✅ Chunk 2 saved to: chunks_for_testing\\beta-marketPlace_for_testing_chunk_2.html\n",
      "✅ Chunk 3 saved to: chunks_for_testing\\beta-marketPlace_for_testing_chunk_3.html\n",
      "✅ Chunk 4 saved to: chunks_for_testing\\beta-marketPlace_for_testing_chunk_4.html\n",
      "✅ Chunk 5 saved to: chunks_for_testing\\beta-marketPlace_for_testing_chunk_5.html\n",
      "✅ Chunk 6 saved to: chunks_for_testing\\beta-marketPlace_for_testing_chunk_6.html\n",
      "✅ Chunk 7 saved to: chunks_for_testing\\beta-marketPlace_for_testing_chunk_7.html\n",
      "✅ Chunk 8 saved to: chunks_for_testing\\beta-marketPlace_for_testing_chunk_8.html\n",
      "✅ Chunk 9 saved to: chunks_for_testing\\beta-marketPlace_for_testing_chunk_9.html\n",
      "✅ Chunk 10 saved to: chunks_for_testing\\beta-marketPlace_for_testing_chunk_10.html\n",
      "✅ Chunk 11 saved to: chunks_for_testing\\beta-marketPlace_for_testing_chunk_11.html\n",
      "✅ Chunk 12 saved to: chunks_for_testing\\beta-marketPlace_for_testing_chunk_12.html\n",
      "✅ Chunk 13 saved to: chunks_for_testing\\beta-marketPlace_for_testing_chunk_13.html\n",
      "✅ Chunk 14 saved to: chunks_for_testing\\beta-marketPlace_for_testing_chunk_14.html\n",
      "✅ Chunk 15 saved to: chunks_for_testing\\beta-marketPlace_for_testing_chunk_15.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Paths\n",
    "input_html_path = 'beta-marketPlace.html'  # Original HTML\n",
    "output_folder = 'chunks_for_testing'  # Folder to save the chunks\n",
    "\n",
    "# Function to create folder if it doesn't exist\n",
    "def create_folder(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        print(f\" Folder '{folder_path}' created.\")\n",
    "    else:\n",
    "        print(f\" Folder '{folder_path}' already exists.\")\n",
    "\n",
    "# Function to extract meaningful testing elements and split into chunks\n",
    "def extract_and_chunk_elements(input_html_path, output_folder, chunk_size=50):\n",
    "    with open(input_html_path, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "\n",
    "    # Parse the full HTML\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Create a new BeautifulSoup object for the cleaned output\n",
    "    new_soup = BeautifulSoup(\"<html><body></body></html>\", 'html.parser')\n",
    "\n",
    "    # Elements important for Selenium Testing\n",
    "    important_tags = []\n",
    "\n",
    "    # --- Form Controls ---\n",
    "    important_tags += soup.find_all(['input', 'button', 'select', 'textarea'])\n",
    "\n",
    "    # --- Links that can navigate ---\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        if link['href'] != '#' and not link['href'].startswith('javascript'):\n",
    "            important_tags.append(link)\n",
    "\n",
    "    # --- Headings ---\n",
    "    important_tags += soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
    "\n",
    "    # --- List items ---\n",
    "    important_tags += soup.find_all('li')\n",
    "\n",
    "    # --- Optional: Divs or spans that contain visible text or action ---\n",
    "    for tag in soup.find_all(['div', 'span']):\n",
    "        if tag.get_text(strip=True):  # Only if they have visible text\n",
    "            important_tags.append(tag)\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    create_folder(output_folder)\n",
    "\n",
    "    # Split into chunks\n",
    "    total_elements = len(important_tags)\n",
    "    chunk_count = (total_elements // chunk_size) + (1 if total_elements % chunk_size else 0)\n",
    "\n",
    "    for i in range(chunk_count):\n",
    "        chunk_start = i * chunk_size\n",
    "        chunk_end = chunk_start + chunk_size\n",
    "\n",
    "        # Create a new soup object for the chunk\n",
    "        chunk_soup = BeautifulSoup(\"<html><body></body></html>\", 'html.parser')\n",
    "\n",
    "        # Append a chunk of elements to the body\n",
    "        for tag in important_tags[chunk_start:chunk_end]:\n",
    "            chunk_soup.body.append(tag)\n",
    "\n",
    "        # File path for the chunk\n",
    "        chunk_file_path = os.path.join(output_folder, f\"beta-marketPlace_for_testing_chunk_{i+1}.html\")\n",
    "\n",
    "        # Write the chunk to a new HTML file\n",
    "        with open(chunk_file_path, 'w', encoding='utf-8') as output_file:\n",
    "            output_file.write(chunk_soup.prettify())\n",
    "        \n",
    "        print(f\" Chunk {i+1} saved to: {chunk_file_path}\")\n",
    "\n",
    "# Run the extraction and chunking\n",
    "extract_and_chunk_elements(input_html_path, output_folder, chunk_size=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating File Structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created folder: c:\\genai\\ai_for_automation\\selenium_pytest_project\n",
      "✅ Created subfolder: c:\\genai\\ai_for_automation\\selenium_pytest_project\\configurations\n",
      "✅ Created subfolder: c:\\genai\\ai_for_automation\\selenium_pytest_project\\page_objects\n",
      "✅ Created subfolder: c:\\genai\\ai_for_automation\\selenium_pytest_project\\test_cases\n",
      "✅ Created subfolder: c:\\genai\\ai_for_automation\\selenium_pytest_project\\test_data\n",
      "✅ Created subfolder: c:\\genai\\ai_for_automation\\selenium_pytest_project\\utilities\n",
      "✅ Created subfolder: c:\\genai\\ai_for_automation\\selenium_pytest_project\\reports\n",
      "✅ Folder structure created successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the folder structure\n",
    "folder_structure = {\n",
    "    \"selenium_pytest_project\": {\n",
    "        \"configurations\": [],\n",
    "        \"page_objects\": [],\n",
    "        \"test_cases\": [],\n",
    "        \"test_data\": [],\n",
    "        \"utilities\": [],\n",
    "        \"reports\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to create folders\n",
    "def create_folders(base_path, folder_structure):\n",
    "    for folder, subfolders in folder_structure.items():\n",
    "        folder_path = os.path.join(base_path, folder)\n",
    "        \n",
    "        # Create the main project folder\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "            print(f\" Created folder: {folder_path}\")\n",
    "        \n",
    "        # Create subfolders inside each main folder\n",
    "        for subfolder in subfolders:\n",
    "            subfolder_path = os.path.join(folder_path, subfolder)\n",
    "            if not os.path.exists(subfolder_path):\n",
    "                os.makedirs(subfolder_path)\n",
    "                print(f\" Created subfolder: {subfolder_path}\")\n",
    "\n",
    "# Base path where the project folder will be created\n",
    "base_path = os.getcwd()  # Current working directory\n",
    "\n",
    "# Create the folder structure\n",
    "create_folders(base_path, folder_structure)\n",
    "\n",
    "print(\" Folder structure created successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General conftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'access_token' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 85\u001b[0m\n\u001b[0;32m     82\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://beta-marketplace.logitech.com/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Run function\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m \u001b[43mgenerate_conftest_with_openai\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 53\u001b[0m, in \u001b[0;36mgenerate_conftest_with_openai\u001b[1;34m(url, output_folder)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Prepare a short + light prompt (no chunks, only instructions)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYou are an expert in Selenium + Pytest automation framework.\u001b[39m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[38;5;124mPlease generate a clean, production-ready `conftest.py` file using the following best practices:\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124mOutput only the Python code in a proper ```python``` code block.\u001b[39m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     51\u001b[0m     client \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mOpenAI(\n\u001b[0;32m     52\u001b[0m         base_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://stg-logiai-service.np.logitech.io/openai/v1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m---> 53\u001b[0m         api_key\u001b[38;5;241m=\u001b[39m\u001b[43maccess_token\u001b[49m  \u001b[38;5;66;03m# Your correct access_token\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     )\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m         completion \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     58\u001b[0m             model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     59\u001b[0m             messages\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}],\n\u001b[0;32m     60\u001b[0m             stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     61\u001b[0m             max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8000\u001b[39m,\n\u001b[0;32m     62\u001b[0m         )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'access_token' is not defined"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Function to extract code from the OpenAI response text\n",
    "def extract_code(response_text):\n",
    "    code_blocks = response_text.split(\"```python\")\n",
    "    if len(code_blocks) > 1:\n",
    "        return code_blocks[1].split(\"```\")[0].strip()\n",
    "    return response_text.strip()\n",
    "\n",
    "# Function to interact with the OpenAI API to generate conftest.py\n",
    "def generate_conftest_with_openai(url, output_folder):\n",
    "    # Prepare the configurations folder path\n",
    "    conftest_folder_path = os.path.join(output_folder, \"configurations\")\n",
    "    \n",
    "    # Make sure folder exists\n",
    "    os.makedirs(conftest_folder_path, exist_ok=True)\n",
    "\n",
    "    # Prepare a short + light prompt (no chunks, only instructions)\n",
    "    prompt = f\"\"\"You are an expert in Selenium + Pytest automation framework.\n",
    "\n",
    "Please generate a clean, production-ready `conftest.py` file using the following best practices:\n",
    "\n",
    "**Driver Fixture (`driver`)**:\n",
    "- Use `webdriver_manager` to automatically manage ChromeDriver.\n",
    "- Configure Chrome options with the following:\n",
    "  - `--start-maximized`\n",
    "  - `--disable-notifications`\n",
    "  - `--disable-infobars`\n",
    "  - `--disable-extensions`\n",
    "  - `--no-sandbox`\n",
    "- Enable headless mode if the environment variable `HEADLESS=true` is set.\n",
    "- Set `implicitly_wait(10)` for the WebDriver instance.\n",
    "- Use logging to indicate driver setup and teardown.\n",
    "- Use `scope=\"session\"` to initialize the WebDriver **only once** per Pytest run.\n",
    "\n",
    "**Base URL Fixture (`base_url`)**:\n",
    "- Use `scope=\"session\"` to provide a consistent base URL throughout the session.\n",
    "- Default to: {url}\n",
    "- Allow overriding via `BASE_URL` environment variable.\n",
    "\n",
    "**General Requirements**:\n",
    "- Follow Pytest conventions.\n",
    "- Include useful comments above each fixture explaining its role.\n",
    "- Provide a small example in comments demonstrating how to use both `driver` and `base_url` in a test.\n",
    "\n",
    "Output only the Python code in a proper ```python``` code block.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    client = openai.OpenAI(\n",
    "        base_url=\"https://stg-logiai-service.np.logitech.io/openai/v1\",\n",
    "        api_key=access_token  # Your correct access_token\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            stream=False,\n",
    "            max_tokens=8000,\n",
    "        )\n",
    "\n",
    "        # Extract and clean code\n",
    "        conftest_code = extract_code(completion.choices[0].message.content)\n",
    "\n",
    "        # Save the code\n",
    "        conftest_path = os.path.join(conftest_folder_path, \"conftest.py\")\n",
    "        with open(conftest_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(conftest_code)\n",
    "\n",
    "        print(f\" conftest.py created successfully at {conftest_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Error occurred while generating conftest.py: {e}\")\n",
    "\n",
    "# === Main Run ===\n",
    "# Paths\n",
    "output_folder = r\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\configurations\"\n",
    "\n",
    "# URL to test\n",
    "url = \"https://beta-marketplace.logitech.com/\"\n",
    "\n",
    "# Run function\n",
    "generate_conftest_with_openai(url, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POM Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created Page Object: C:\\genai\\ai_for_automation\\wastage\\pom_chunks\\page_objects\\beta-marketPlace_for_testing_chunk_1.py\n",
      "✅ Created Page Object: C:\\genai\\ai_for_automation\\wastage\\pom_chunks\\page_objects\\beta-marketPlace_for_testing_chunk_10.py\n",
      "✅ Created Page Object: C:\\genai\\ai_for_automation\\wastage\\pom_chunks\\page_objects\\beta-marketPlace_for_testing_chunk_11.py\n",
      "✅ Created Page Object: C:\\genai\\ai_for_automation\\wastage\\pom_chunks\\page_objects\\beta-marketPlace_for_testing_chunk_12.py\n",
      "✅ Created Page Object: C:\\genai\\ai_for_automation\\wastage\\pom_chunks\\page_objects\\beta-marketPlace_for_testing_chunk_13.py\n",
      "✅ Created Page Object: C:\\genai\\ai_for_automation\\wastage\\pom_chunks\\page_objects\\beta-marketPlace_for_testing_chunk_14.py\n",
      "✅ Created Page Object: C:\\genai\\ai_for_automation\\wastage\\pom_chunks\\page_objects\\beta-marketPlace_for_testing_chunk_15.py\n",
      "✅ Created Page Object: C:\\genai\\ai_for_automation\\wastage\\pom_chunks\\page_objects\\beta-marketPlace_for_testing_chunk_2.py\n",
      "✅ Created Page Object: C:\\genai\\ai_for_automation\\wastage\\pom_chunks\\page_objects\\beta-marketPlace_for_testing_chunk_3.py\n",
      "✅ Created Page Object: C:\\genai\\ai_for_automation\\wastage\\pom_chunks\\page_objects\\beta-marketPlace_for_testing_chunk_4.py\n",
      "✅ Created Page Object: C:\\genai\\ai_for_automation\\wastage\\pom_chunks\\page_objects\\beta-marketPlace_for_testing_chunk_5.py\n",
      "✅ Created Page Object: C:\\genai\\ai_for_automation\\wastage\\pom_chunks\\page_objects\\beta-marketPlace_for_testing_chunk_6.py\n",
      "✅ Created Page Object: C:\\genai\\ai_for_automation\\wastage\\pom_chunks\\page_objects\\beta-marketPlace_for_testing_chunk_7.py\n",
      "✅ Created Page Object: C:\\genai\\ai_for_automation\\wastage\\pom_chunks\\page_objects\\beta-marketPlace_for_testing_chunk_8.py\n",
      "✅ Created Page Object: C:\\genai\\ai_for_automation\\wastage\\pom_chunks\\page_objects\\beta-marketPlace_for_testing_chunk_9.py\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Function to extract code from OpenAI response\n",
    "def extract_code(response_text):\n",
    "    code_blocks = response_text.split(\"```python\")\n",
    "    if len(code_blocks) > 1:\n",
    "        return code_blocks[1].split(\"```\")[0].strip()\n",
    "    return response_text.strip()\n",
    "\n",
    "# Function to read all chunk files from a folder\n",
    "def read_chunks_from_folder(chunks_folder):\n",
    "    chunk_files = []\n",
    "    for filename in os.listdir(chunks_folder):\n",
    "        file_path = os.path.join(chunks_folder, filename)\n",
    "        if filename.endswith(\".html\") or filename.endswith(\".txt\"):\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                chunk_content = file.read()\n",
    "                chunk_files.append((filename, chunk_content))\n",
    "    return chunk_files\n",
    "\n",
    "# Function to generate Page Object files\n",
    "def generate_pom_from_chunks(project_folder, chunks_folder):\n",
    "    # Define page_objects folder path\n",
    "    page_objects_folder = os.path.join(project_folder, \"page_objects\")\n",
    "    os.makedirs(page_objects_folder, exist_ok=True)\n",
    "\n",
    "    # Read all chunks\n",
    "    chunks = read_chunks_from_folder(chunks_folder)\n",
    "    if not chunks:\n",
    "        print(f\" No valid HTML chunk files found in {chunks_folder}\")\n",
    "        return\n",
    "\n",
    "    # OpenAI client setup\n",
    "    client = openai.OpenAI(\n",
    "        base_url=\"https://stg-logiai-service.np.logitech.io/openai/v1\",\n",
    "        api_key=access_token  # Make sure this is already available\n",
    "    )\n",
    "\n",
    "    for filename, chunk_content in chunks:\n",
    "        # Create a simple prompt for each chunk\n",
    "        prompt = f\"\"\"\n",
    "You are an expert in building Selenium Page Object Model (POM) classes.\n",
    "\n",
    "Below is an HTML snippet:\n",
    "{chunk_content}\n",
    "\n",
    "Based on this HTML, generate a Python POM class:\n",
    "- Class name should be based on the file name (without extension), in PascalCase.\n",
    "- Use Selenium locators and `By`.\n",
    "- Include an `__init__` method with a WebDriver instance.\n",
    "- For each interactive element (like buttons), define methods with:\n",
    "  - WebDriverWait and expected_conditions for reliable interaction\n",
    "  - Scroll into view using JavaScript before clicking\n",
    "  - Retry logic for StaleElementReferenceException\n",
    "  - Fallback click using ActionChains or JavaScript if normal click fails\n",
    "- Follow production-level coding standards and error handling\n",
    "- Do not include test cases\n",
    "- Wrap the final code in a Python code block\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                stream=False,\n",
    "                max_tokens=1200,\n",
    "            )\n",
    "\n",
    "            # Extract the code\n",
    "            pom_code = extract_code(completion.choices[0].message.content)\n",
    "\n",
    "            # Convert filename to class name\n",
    "            base_name = os.path.splitext(filename)[0]\n",
    "            class_name = \"\".join(word.capitalize() for word in base_name.split(\"_\"))\n",
    "\n",
    "            # Save file\n",
    "            pom_file_path = os.path.join(page_objects_folder, f\"{base_name}.py\")\n",
    "            with open(pom_file_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(pom_code)\n",
    "\n",
    "            print(f\" Created Page Object: {pom_file_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" Error processing {filename}: {e}\")\n",
    "\n",
    "# === Main Run ===\n",
    "# Input paths\n",
    "waste_folder = r\"C:\\genai\\ai_for_automation\\wastage\\pom_chunks\"\n",
    "chunks_folder = r\"C:\\genai\\ai_for_automation\\chunks_for_testing\"\n",
    "\n",
    "# Run function\n",
    "generate_pom_from_chunks(waste_folder, chunks_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined file created at: C:\\genai\\ai_for_automation\\wastage\\pom_chunks\\page_objects\\page_objects_combined.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def combine_chunks_as_is(folder_path, output_file_path):\n",
    "    try:\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "            for filename in sorted(os.listdir(folder_path)):\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                if os.path.isfile(file_path) and filename.endswith('.py'):\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        content = file.read()\n",
    "                        output_file.write(f\"# ----- {filename} -----\\n\")\n",
    "                        output_file.write(content + \"\\n\\n\")\n",
    "        print(f\" Combined file created at: {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error: {e}\")\n",
    "\n",
    "# Example usage\n",
    "folder_path = r\"C:\\genai\\ai_for_automation\\wastage\\pom_chunks\\page_objects\"\n",
    "output_file_path = r\"C:\\genai\\ai_for_automation\\wastage\\pom_chunks\\page_objects\\page_objects_combined.py\"\n",
    "\n",
    "combine_chunks_as_is(folder_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combined output for page object chunks (input file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://stg-logiai-service.np.logitech.io/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:✅ Optimized file created at C:\\genai\\ai_for_automation\\selenium_pytest_project\\page_objects\\page_objects.py\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def read_single_file(file_path):\n",
    "    \"\"\"Reads and returns the content of a single file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error reading file {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def extract_code(response_text):\n",
    "    \"\"\"Extracts Python code from markdown-style response.\"\"\" \n",
    "    if \"```python\" in response_text:\n",
    "        return response_text.split(\"```python\")[1].split(\"```\")[0].strip()\n",
    "    return response_text.strip()\n",
    "\n",
    "def send_to_llm(file_content, api_key, base_url):\n",
    "    \"\"\"Sends a single file's content to the LLM and returns optimized Python code.\"\"\"\n",
    "    client = openai.OpenAI(\n",
    "        base_url=base_url,\n",
    "        api_key=api_key\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a Selenium expert using Pytest with the Page Object Model (POM).\n",
    "\n",
    "You will be given a raw Page Object class file. Please do the following:\n",
    "\n",
    "1. Do NOT change any of the existing locators (e.g., self.username_input = ...).\n",
    "2. Do NOT rename or merge any methods.\n",
    "3. Ensure that all functions are retained and NO duplicates exist.\n",
    "4. Clean the code, maintain structure, and preserve the original functionality.\n",
    "\n",
    "IMPORTANT:\n",
    "- Keep all By locators and element actions intact.\n",
    "- The final code should contain all methods from the original, even if they're similar.\n",
    "- Remove duplicate method definitions (same method name more than once).\n",
    "- Preserve method order and structure.\n",
    "\n",
    "Now clean and return the corrected class file for the following code:\n",
    "\n",
    "{file_content}\n",
    "\"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            stream=False,\n",
    "            max_tokens=9000,\n",
    "        )\n",
    "        return extract_code(completion.choices[0].message.content.strip())\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error while sending content to LLM: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def create_output_file(output_file_path, optimized_content):\n",
    "    \"\"\"Writes optimized code to output file.\"\"\"\n",
    "    try:\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "            output_file.write(optimized_content)\n",
    "        logger.info(f\" Optimized file created at {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error writing to output file: {e}\")\n",
    "\n",
    "def process_single_file(input_file_path, output_file_path, api_key, base_url):\n",
    "    \"\"\"Main function for processing a single file.\"\"\"\n",
    "    file_content = read_single_file(input_file_path)\n",
    "    if not file_content:\n",
    "        logger.warning(f\"No content found in file: {input_file_path}\")\n",
    "        return\n",
    "\n",
    "    optimized_content = send_to_llm(file_content, api_key, base_url)\n",
    "    if not optimized_content:\n",
    "        logger.warning(\"No optimized content received from LLM.\")\n",
    "        return\n",
    "\n",
    "    create_output_file(output_file_path, optimized_content)\n",
    "\n",
    "# Example usage\n",
    "input_file_path = r\"C:\\genai\\ai_for_automation\\wastage\\page_objects_combined.py\"\n",
    "output_file_path = r\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\page_objects\\page_objects.py\"\n",
    "api_key = access_token  # Make sure access_token is defined or imported\n",
    "base_url = \"https://stg-logiai-service.np.logitech.io/openai/v1\"\n",
    "\n",
    "process_single_file(input_file_path, output_file_path, api_key, base_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the chunks of pom (input folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Optimized file created at C:\\genai\\ai_for_automation\\selenium_pytest_project\\page_objects\\try_page_objects.py\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "def read_all_chunks_from_folder(folder_path):\n",
    "    \"\"\"Reads and combines all .py files from the given folder.\"\"\"\n",
    "    combined_content = \"\"\n",
    "    for filename in sorted(os.listdir(folder_path)):\n",
    "        if filename.endswith(\".py\"):\n",
    "            with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as f:\n",
    "                combined_content += f.read() + \"\\n\\n\"\n",
    "    return combined_content\n",
    "\n",
    "def extract_code(response_text):\n",
    "    \"\"\"Extracts Python code from markdown-style response.\"\"\" \n",
    "    if \"```python\" in response_text:\n",
    "        return response_text.split(\"```python\")[1].split(\"```\")[0].strip()\n",
    "    return response_text.strip()\n",
    "\n",
    "def send_to_llm(file_content, api_key, base_url):\n",
    "    \"\"\"Sends the combined content to the LLM and returns optimized code.\"\"\"\n",
    "    client = openai.OpenAI(\n",
    "        base_url=base_url,\n",
    "        api_key=api_key\n",
    "    )\n",
    "\n",
    "    prompt = (\n",
    "        \"You are a Python Selenium expert following the Page Object Model (POM).\\n\"\n",
    "        \"Below is a class split across chunks. Please:\\n\"\n",
    "        \"- Combine all chunks into one clean class.\\n\"\n",
    "        \"- Keep ALL functions (do not remove any).\\n\"\n",
    "        \"- Do NOT change any locators.\\n\"\n",
    "        \"- Remove duplicate function names.\\n\"\n",
    "        \"- Ensure class is clean and well-structured.\\n\"\n",
    "        \"- go through every function if there is any logic mistake try to write a comment after the function. \\n\"\n",
    "        \"- try to create all the function in one single class\"\n",
    "        f\"{file_content}\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            stream=False,\n",
    "            max_tokens=9000,\n",
    "        )\n",
    "        return extract_code(completion.choices[0].message.content.strip())\n",
    "    except Exception as e:\n",
    "        print(f\"Error from LLM: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def create_output_file(output_file_path, optimized_content):\n",
    "    \"\"\"Writes optimized code to the specified output file.\"\"\"\n",
    "    try:\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "            output_file.write(optimized_content)\n",
    "        print(f\" Optimized file created at {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to file: {e}\")\n",
    "\n",
    "def process_folder(folder_path, output_file_path, api_key, base_url):\n",
    "    \"\"\"Reads all chunk files, combines them, sends to LLM, and writes result.\"\"\"\n",
    "    file_content = read_all_chunks_from_folder(folder_path)\n",
    "    if not file_content:\n",
    "        print(f\"No Python files found in: {folder_path}\")\n",
    "        return\n",
    "\n",
    "    optimized_content = send_to_llm(file_content, api_key, base_url)\n",
    "    if not optimized_content:\n",
    "        print(\"No optimized content returned.\")\n",
    "        return\n",
    "\n",
    "    create_output_file(output_file_path, optimized_content)\n",
    "\n",
    "# Example usage\n",
    "input_folder = r\"C:\\genai\\ai_for_automation\\wastage\\pom_chunks\\page_objects\"\n",
    "output_file = r\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\page_objects\\try_page_objects.py\"\n",
    "api_key = access_token  # Replace or define this\n",
    "base_url = \"https://stg-logiai-service.np.logitech.io/openai/v1\"\n",
    "\n",
    "process_folder(input_folder, output_file, api_key, base_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://stg-logiai-service.np.logitech.io/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:✅ Optimized file created at C:\\genai\\ai_for_automation\\selenium_pytest_project\\page_objects\\page_objects.py\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def read_single_file(file_path):\n",
    "    \"\"\"Reads and returns the content of a single file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error reading file {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def extract_code(response_text):\n",
    "    \"\"\"Extracts Python code from markdown-style response.\"\"\" \n",
    "    if \"```python\" in response_text:\n",
    "        return response_text.split(\"```python\")[1].split(\"```\")[0].strip()\n",
    "    return response_text.strip()\n",
    "\n",
    "def send_to_llm(file_content, api_key, base_url):\n",
    "    \"\"\"Sends a single file's content to the LLM and returns optimized Python code.\"\"\"\n",
    "    client = openai.OpenAI(\n",
    "        base_url=base_url,\n",
    "        api_key=api_key\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an expert in Selenium and Pytest automation.\n",
    "\n",
    "You will be provided with a raw test case class file. Your task is to:\n",
    "\n",
    "1. **Do NOT modify** any existing locators (e.g., self.username_input = ...).\n",
    "2. **Do NOT rename or merge** any methods.\n",
    "3. **Ensure that all methods are kept** without duplication. If any method is duplicated, remove the duplicates.\n",
    "4. **Preserve the structure and functionality** of the original code, ensuring that all methods and logic are intact.\n",
    "5. **Clean the code**, removing unnecessary or redundant lines, but maintaining clarity and readability.\n",
    "\n",
    "IMPORTANT:\n",
    "- Keep all By locators and element actions as they are, without any changes.\n",
    "- Ensure the final output contains **all methods** from the original file, even if they appear similar.\n",
    "- **Remove duplicate methods** (same method name, same functionality, appearing more than once).\n",
    "- **Preserve the method order** and **class structure** exactly as in the original file.\n",
    "\n",
    "Return the corrected class file, maintaining the original functionality, for the following input code:\n",
    "\n",
    "{file_content}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            stream=False,\n",
    "            max_tokens=9000,\n",
    "        )\n",
    "        return extract_code(completion.choices[0].message.content.strip())\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error while sending content to LLM: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def create_output_file(output_file_path, optimized_content):\n",
    "    \"\"\"Writes optimized code to output file.\"\"\"\n",
    "    try:\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "            output_file.write(optimized_content)\n",
    "        logger.info(f\" Optimized file created at {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error writing to output file: {e}\")\n",
    "\n",
    "def process_single_file(input_file_path, output_file_path, api_key, base_url):\n",
    "    \"\"\"Main function for processing a single file.\"\"\"\n",
    "    file_content = read_single_file(input_file_path)\n",
    "    if not file_content:\n",
    "        logger.warning(f\"No content found in file: {input_file_path}\")\n",
    "        return\n",
    "\n",
    "    optimized_content = send_to_llm(file_content, api_key, base_url)\n",
    "    if not optimized_content:\n",
    "        logger.warning(\"No optimized content received from LLM.\")\n",
    "        return\n",
    "\n",
    "    create_output_file(output_file_path, optimized_content)\n",
    "\n",
    "# Example usage\n",
    "input_file_path = r\"C:\\genai\\ai_for_automation\\wastage\\page_objects_combined.py\"\n",
    "output_file_path = r\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\page_objects\\page_objects.py\"\n",
    "api_key = access_token  # Make sure access_token is defined or imported\n",
    "base_url = \"https://stg-logiai-service.np.logitech.io/openai/v1\"\n",
    "\n",
    "process_single_file(input_file_path, output_file_path, api_key, base_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunks for test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing chunk 1/15 ---\n",
      "\n",
      "--- Processing chunk 2/15 ---\n",
      "\n",
      "--- Processing chunk 3/15 ---\n",
      "\n",
      "--- Processing chunk 4/15 ---\n",
      "\n",
      "--- Processing chunk 5/15 ---\n",
      "\n",
      "--- Processing chunk 6/15 ---\n",
      "\n",
      "--- Processing chunk 7/15 ---\n",
      "\n",
      "--- Processing chunk 8/15 ---\n",
      "\n",
      "--- Processing chunk 9/15 ---\n",
      "\n",
      "--- Processing chunk 10/15 ---\n",
      "\n",
      "--- Processing chunk 11/15 ---\n",
      "\n",
      "--- Processing chunk 12/15 ---\n",
      "\n",
      "--- Processing chunk 13/15 ---\n",
      "\n",
      "--- Processing chunk 14/15 ---\n",
      "\n",
      "--- Processing chunk 15/15 ---\n",
      "Final test file saved at: C:\\genai\\ai_for_automation\\selenium_pytest_project\\test_cases\\try_test_final_combined.py\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# === Utility Functions ===\n",
    "\n",
    "def read_files_from_folder(folder_path):\n",
    "    contents = []\n",
    "    try:\n",
    "        for filename in sorted(os.listdir(folder_path)):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    contents.append(file.read())\n",
    "        return contents\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading files from folder: {e}\")\n",
    "        return []\n",
    "\n",
    "def read_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def extract_code(response_text):\n",
    "    if \"```python\" in response_text:\n",
    "        return response_text.split(\"```python\")[1].split(\"```\")[0].strip()\n",
    "    return response_text.strip()\n",
    "\n",
    "def send_to_llm_single_chunk(html_chunk, pom_code, conftest_code, api_key, base_url):\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI(api_key=api_key, base_url=base_url)\n",
    "\n",
    "    prompt = (\n",
    "        \"You are an expert in Selenium and Pytest.\\n\"\n",
    "        \"Generate a Python test function using pytest and the provided conftest fixture and Page Object Model (POM).\\n\"\n",
    "        \"Use correct imports.\\n\\n\"\n",
    "        f\"HTML Snippet:\\n{html_chunk}\\n\\n\"\n",
    "        f\"POM Code:\\n{pom_code}\\n\\n\"\n",
    "        f\"conftest.py:\\n{conftest_code}\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=4096\n",
    "        )\n",
    "        return extract_code(completion.choices[0].message.content.strip())\n",
    "    except Exception as e:\n",
    "        print(f\"LLM call failed: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "\n",
    "def save_combined_test(output_file_path, test_code):\n",
    "    try:\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(test_code)\n",
    "        print(f\"Final test file saved at: {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving final test file: {e}\")\n",
    "\n",
    "# === Main Function ===\n",
    "\n",
    "def generate_single_test_file(html_folder, pom_file_path, conftest_path, output_file_path, api_key, base_url):\n",
    "    html_chunks = read_files_from_folder(html_folder)\n",
    "    pom_code = read_file(pom_file_path)\n",
    "    conftest_code = read_file(conftest_path)\n",
    "\n",
    "    combined_test_code = \"\"\n",
    "\n",
    "    for i, chunk in enumerate(html_chunks):\n",
    "        print(f\"\\n--- Processing chunk {i+1}/{len(html_chunks)} ---\")\n",
    "        test_code = send_to_llm_single_chunk(chunk, pom_code, conftest_code, api_key, base_url)\n",
    "        if test_code:\n",
    "            combined_test_code += f\"# === Test from chunk {i+1} ===\\n{test_code}\\n\\n\"\n",
    "        else:\n",
    "            print(f\"No test code received for chunk {i+1}.\")\n",
    "\n",
    "    if combined_test_code:\n",
    "        save_combined_test(output_file_path, combined_test_code)\n",
    "    else:\n",
    "        print(\"No test code generated.\")\n",
    "\n",
    "\n",
    "# === Update these with correct paths ===\n",
    "\n",
    "html_folder = r\"C:\\genai\\ai_for_automation\\chunks_for_testing\"\n",
    "pom_file_path = r\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\page_objects\\page_objects.py\"  # Use correct single POM file\n",
    "conftest_path = r\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\configurations\\configurations\\conftest.py\"\n",
    "output_file_path = r\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\test_cases\\try_test_final_combined.py\"\n",
    "api_key = access_token\n",
    "base_url = \"https://stg-logiai-service.np.logitech.io/openai/v1\"\n",
    "\n",
    "generate_single_test_file(html_folder, pom_file_path, conftest_path, output_file_path, api_key, base_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a Selenium expert using Pytest.\n",
    "\n",
    "You will be given a merged raw test case file composed of multiple test chunks. Your task is to:\n",
    "\n",
    "1. Consolidate the code into a **single clean test file**.\n",
    "2. **Do NOT remove or rename any test functions** — all test logic must be preserved.\n",
    "3. **Eliminate duplicate imports** and organize them properly.\n",
    "4. Remove **duplicate test cases** (same name and logic).\n",
    "5. Ensure that **each test function is unique**, well-structured, and properly formatted.\n",
    "6. Clean and organize fixtures and helper methods without changing their behavior.\n",
    "\n",
    "IMPORTANT:\n",
    "- **Preserve test logic and data** from all chunks.\n",
    "- Ensure **all test cases and fixtures are retained** unless they are exact duplicates.\n",
    "- Adjust **import paths consistently** (e.g., unify `from POM` vs `from pom` vs `from plugin_marketplace_page`).\n",
    "- Ensure **no syntax errors** and that the file is ready to run with `pytest`.\n",
    "\n",
    "Return a single, clean, final test file with all necessary test functions and imports.\n",
    "\n",
    "Here is the raw test file:\n",
    "\n",
    "{file_content}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###final test cases production  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://stg-logiai-service.np.logitech.io/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:✅ Optimized file created at C:\\genai\\ai_for_automation\\selenium_pytest_project\\test_cases\\try_test_case.py\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def read_single_file(file_path):\n",
    "    \"\"\"Reads and returns the content of a single file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error reading file {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def extract_code(response_text):\n",
    "    \"\"\"Extracts Python code from markdown-style response.\"\"\" \n",
    "    if \"```python\" in response_text:\n",
    "        return response_text.split(\"```python\")[1].split(\"```\")[0].strip()\n",
    "    return response_text.strip()\n",
    "\n",
    "def send_to_llm(file_content, api_key, base_url):\n",
    "    \"\"\"Sends a single file's content to the LLM and returns optimized Python code.\"\"\"\n",
    "    client = openai.OpenAI(\n",
    "        base_url=base_url,\n",
    "        api_key=api_key\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a Selenium expert using Pytest.\n",
    "\n",
    "You will be given a merged raw test case file composed of multiple test chunks. Your task is to:\n",
    "\n",
    "1. Consolidate the code into a **single clean test file**.\n",
    "2. **Do NOT remove or rename any test functions** — all test logic must be preserved.\n",
    "3. **Eliminate duplicate imports** and organize them properly.\n",
    "4. Remove **duplicate test cases** (same name and logic).\n",
    "5. Ensure that **each test function is unique**, well-structured, and properly formatted.\n",
    "6. Clean and organize fixtures and helper methods without changing their behavior.\n",
    "\n",
    "IMPORTANT:\n",
    "- **Preserve test logic and data** from all chunks.\n",
    "- Ensure **all test cases and fixtures are retained** unless they are exact duplicates.\n",
    "- Adjust **import paths consistently** (e.g., unify `from POM` vs `from pom` vs `from plugin_marketplace_page`).\n",
    "- Ensure **no syntax errors** and that the file is ready to run with `pytest`.\n",
    "\n",
    "Return a single, clean, final test file with all necessary test functions and imports.\n",
    "\n",
    "Here is the raw test file:\n",
    "\n",
    "{file_content}\n",
    "\"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            stream=False,\n",
    "            max_tokens=9000,\n",
    "        )\n",
    "        return extract_code(completion.choices[0].message.content.strip())\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error while sending content to LLM: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def create_output_file(output_file_path, optimized_content):\n",
    "    \"\"\"Writes optimized code to output file.\"\"\"\n",
    "    try:\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "            output_file.write(optimized_content)\n",
    "        logger.info(f\" Optimized file created at {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error writing to output file: {e}\")\n",
    "\n",
    "def process_single_file(input_file_path, output_file_path, api_key, base_url):\n",
    "    \"\"\"Main function for processing a single file.\"\"\"\n",
    "    file_content = read_single_file(input_file_path)\n",
    "    if not file_content:\n",
    "        logger.warning(f\"No content found in file: {input_file_path}\")\n",
    "        return\n",
    "\n",
    "    optimized_content = send_to_llm(file_content, api_key, base_url)\n",
    "    if not optimized_content:\n",
    "        logger.warning(\"No optimized content received from LLM.\")\n",
    "        return\n",
    "\n",
    "    create_output_file(output_file_path, optimized_content)\n",
    "\n",
    "# Example usage\n",
    "input_file_path = r\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\test_cases\\try_test_final_combined.py\"\n",
    "output_file_path = r\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\test_cases\\try_test_case.py\"\n",
    "api_key = access_token  # Make sure access_token is defined or imported\n",
    "base_url = \"https://stg-logiai-service.np.logitech.io/openai/v1\"\n",
    "\n",
    "process_single_file(input_file_path, output_file_path, api_key, base_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrape (pom, test data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'C:\\\\genai\\x07i_for_automation\\\\selenium_pytest_project\\\\page_objects\\\\page_objects.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 83\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m imports \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m pom_code \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m test_code\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Run generation\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m pom_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpom_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m test_data \u001b[38;5;241m=\u001b[39m load_json(test_data_path)\n\u001b[0;32m     85\u001b[0m code \u001b[38;5;241m=\u001b[39m generate_combined_script(pom_data, test_data)\n",
      "Cell \u001b[1;32mIn[51], line 14\u001b[0m, in \u001b[0;36mload_json\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_json\u001b[39m(path):\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'C:\\\\genai\\x07i_for_automation\\\\selenium_pytest_project\\\\page_objects\\\\page_objects.py'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Input paths\n",
    "pom_path = Path(\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\page_objects\\page_objects.py\")\n",
    "test_data_path = Path(\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\test_cases\\test_case.py\")\n",
    "\n",
    "# Output path\n",
    "output_path = Path(\"output/test_install_button.py\")\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def generate_pom_class(pom):\n",
    "    class_name = pom[\"class_name\"]\n",
    "    elements = pom[\"elements\"]\n",
    "    actions = pom[\"actions\"]\n",
    "\n",
    "    lines = [\n",
    "        f\"class {class_name}:\",\n",
    "        f\"    def __init__(self, driver):\",\n",
    "        f\"        self.driver = driver\",\n",
    "        \"\"\n",
    "    ]\n",
    "\n",
    "    for el in elements:\n",
    "        if \"{app_id}\" in el[\"value\"]:\n",
    "            line = f\"    def get_{el['name']}(self, app_id):\"\n",
    "            val = el[\"value\"].replace(\"{app_id}\", \"' + app_id + '\")\n",
    "            body = f\"        return self.driver.find_element({el['by']}, f\\\"{val}\\\")\"\n",
    "        else:\n",
    "            line = f\"    def get_{el['name']}(self):\"\n",
    "            body = f\"        return self.driver.find_element({el['by']}, \\\"{el['value']}\\\")\"\n",
    "        lines += [line, body, \"\"]\n",
    "\n",
    "    for action in actions:\n",
    "        name = action[\"name\"]\n",
    "        el = action[\"element\"]\n",
    "        params = \", \".join([\"self\"] + action.get(\"params\", []))\n",
    "        call_args = \", \".join(action.get(\"params\", []))\n",
    "        lines += [\n",
    "            f\"    def {name}({params}):\",\n",
    "            f\"        self.get_{el}({call_args}).click()\",\n",
    "            \"\"\n",
    "        ]\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def generate_test_case(test, pom_class_name, url_suffix):\n",
    "    return f\"\"\"\n",
    "def {test['test_name']}(driver, base_url):\n",
    "    driver.get(base_url + \"{url_suffix}\")\n",
    "    page = {pom_class_name}(driver)\n",
    "\n",
    "    app_id = \"{test['app_id']}\"\n",
    "    page.click_install_button(app_id)\n",
    "\n",
    "    confirmation = WebDriverWait(driver, 10).until(\n",
    "        EC.visibility_of_element_located((By.CSS_SELECTOR, \"div.install-confirmation\"))\n",
    "    )\n",
    "    assert \"{test['expected_text']}\" in confirmation.text, \"Installation confirmation not found.\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generate_combined_script(pom_data, test_data):\n",
    "    imports = \"\"\"from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pytest\n",
    "\"\"\"\n",
    "\n",
    "    pom_code = generate_pom_class(pom_data)\n",
    "    test_code = generate_test_case(test_data, pom_data[\"class_name\"], pom_data[\"url_suffix\"])\n",
    "    return imports + \"\\n\\n\" + pom_code + \"\\n\" + test_code\n",
    "\n",
    "\n",
    "# Run generation\n",
    "pom_data = load_json(pom_path)\n",
    "test_data = load_json(test_data_path)\n",
    "code = generate_combined_script(pom_data, test_data)\n",
    "\n",
    "# Write output\n",
    "output_path.write_text(code)\n",
    "print(f\" Generated combined POM + test case: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single test cases from chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending single combined HTML chunk to LLM...\n",
      "Final test file saved at: C:\\genai\\AI_for_automation_stage _1.1\\selenium_pytest_project\\test_cases\\test_final_combined.py\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# === Utility Functions ===\n",
    "\n",
    "def read_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def extract_code(response_text):\n",
    "    if \"```python\" in response_text:\n",
    "        return response_text.split(\"```python\")[1].split(\"```\")[0].strip()\n",
    "    return response_text.strip()\n",
    "\n",
    "def send_to_llm_single_chunk(html_combined, pom_code, conftest_code, api_key, base_url):\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI(api_key=api_key, base_url=base_url)\n",
    "\n",
    "    prompt = (\n",
    "        \"You are an expert in Selenium and Pytest.\\n\"\n",
    "        \"Generate a single Python test file using pytest, based on the HTML snippet below.\\n\"\n",
    "        \"Use Page Object Model (POM) functions and conftest fixtures properly.\\n\"\n",
    "        \"Ensure correct and clean imports.\\n\"\n",
    "        \"Do not repeat POM or conftest code.\\n\\n\"\n",
    "        f\"HTML Snippet:\\n{html_combined}\\n\\n\"\n",
    "        f\"POM Code:\\n{pom_code}\\n\\n\"\n",
    "        f\"conftest.py:\\n{conftest_code}\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=4096\n",
    "        )\n",
    "        return extract_code(completion.choices[0].message.content.strip())\n",
    "    except Exception as e:\n",
    "        print(f\"LLM call failed: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def save_combined_test(output_file_path, test_code):\n",
    "    try:\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(test_code)\n",
    "        print(f\"Final test file saved at: {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving final test file: {e}\")\n",
    "\n",
    "# === Main Function ===\n",
    "\n",
    "def generate_test_from_single_html_file(html_file_path, pom_file_path, conftest_path, output_file_path, api_key, base_url):\n",
    "    html_combined = read_file(html_file_path)\n",
    "    pom_code = read_file(pom_file_path)\n",
    "    conftest_code = read_file(conftest_path)\n",
    "\n",
    "    print(\"Sending single combined HTML chunk to LLM...\")\n",
    "\n",
    "    test_code = send_to_llm_single_chunk(html_combined, pom_code, conftest_code, api_key, base_url)\n",
    "\n",
    "    if test_code:\n",
    "        save_combined_test(output_file_path, test_code)\n",
    "    else:\n",
    "        print(\"No test code generated.\")\n",
    "\n",
    "# === Update these with correct paths ===\n",
    "\n",
    "html_file_path = r\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\test_cases\\test_final_combined.py\"\n",
    "pom_file_path = r\"C:\\genai\\AI_for_automation_stage _1.1\\selenium_pytest_project\\page_objects\\combined_output.py\"\n",
    "conftest_path = r\"C:\\genai\\AI_for_automation_stage _1.1\\selenium_pytest_project\\configurations\\conftest.py\"\n",
    "output_file_path = r\"C:\\genai\\AI_for_automation_stage _1.1\\selenium_pytest_project\\test_cases\\test_final_combined.py\"\n",
    "api_key = access_token\n",
    "base_url = \"https://stg-logiai-service.np.logitech.io/openai/v1\"\n",
    "\n",
    "generate_test_from_single_html_file(html_file_path, pom_file_path, conftest_path, output_file_path, api_key, base_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM call failed: Error code: 400 - {'detail': 'Error code: 400 - {\\'error\\': {\\'message\\': \"This model\\'s maximum context length is 128000 tokens. However, your messages resulted in 132501 tokens. Please reduce the length of the messages.\", \\'type\\': \\'invalid_request_error\\', \\'param\\': \\'messages\\', \\'code\\': \\'context_length_exceeded\\'}}'}\n",
      "⚠️ No test code generated.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# === Utility Functions ===\n",
    "\n",
    "def read_files_from_folder(folder_path):\n",
    "    contents = []\n",
    "    try:\n",
    "        for filename in sorted(os.listdir(folder_path)):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    contents.append(file.read())\n",
    "        return \"\\n\\n\".join(contents)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading files from folder: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def read_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def extract_code(response_text):\n",
    "    if \"```python\" in response_text:\n",
    "        return response_text.split(\"```python\")[1].split(\"```\")[0].strip()\n",
    "    return response_text.strip()\n",
    "\n",
    "def send_to_llm_merge_and_optimize(html_combined, pom_code, conftest_code, raw_test_code, api_key, base_url):\n",
    "    client = OpenAI(api_key=api_key, base_url=base_url)\n",
    "\n",
    "    prompt = (\n",
    "        \"You are a senior QA automation engineer.\\n\"\n",
    "        \"Your task is to optimize and clean up the following raw test functions written using Pytest and Selenium.\\n\"\n",
    "        \"Use the provided Page Object Model (POM) and conftest.py fixture correctly.\\n\"\n",
    "        \"Fix duplicate imports, incorrect structure, and ensure the output is ONE clean test file using POM functions and fixtures.\\n\"\n",
    "        \"Only output the final Python test file.\\n\\n\"\n",
    "        f\"HTML Chunks (merged):\\n{html_combined}\\n\\n\"\n",
    "        f\"POM Code:\\n{pom_code}\\n\\n\"\n",
    "        f\"conftest.py:\\n{conftest_code}\\n\\n\"\n",
    "        f\"Raw Combined Test Code:\\n{raw_test_code}\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=4096\n",
    "        )\n",
    "        return extract_code(completion.choices[0].message.content.strip())\n",
    "    except Exception as e:\n",
    "        print(f\"LLM call failed: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def save_final_test(output_file_path, test_code):\n",
    "    try:\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(test_code)\n",
    "        print(f\" Final test file saved at: {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error saving final test file: {e}\")\n",
    "\n",
    "# === Main Function ===\n",
    "\n",
    "def refine_combined_test_case(html_folder, pom_file_path, conftest_path, raw_test_path, output_file_path, api_key, base_url):\n",
    "    html_combined = read_files_from_folder(html_folder)\n",
    "    pom_code = read_file(pom_file_path)\n",
    "    conftest_code = read_file(conftest_path)\n",
    "    raw_test_code = read_file(raw_test_path)\n",
    "\n",
    "    final_test_code = send_to_llm_merge_and_optimize(html_combined, pom_code, conftest_code, raw_test_code, api_key, base_url)\n",
    "\n",
    "    if final_test_code:\n",
    "        save_final_test(output_file_path, final_test_code)\n",
    "    else:\n",
    "        print(\" No test code generated.\")\n",
    "\n",
    "# === Update with actual paths ===\n",
    "\n",
    "html_folder = r\"C:\\genai\\ai_for_automation\\chunks_for_testing\"\n",
    "pom_file_path = r\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\page_objects\\page_objest.py\"\n",
    "conftest_path = r\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\configurations\\configurations\\conftest.py\"\n",
    "raw_test_path = r\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\test_cases\\test_final_combined.py\"\n",
    "output_file_path = r\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\test_cases\\test_final_cleaned.py\"\n",
    "api_key = access_token\n",
    "base_url = \"https://stg-logiai-service.np.logitech.io/openai/v1\"\n",
    "\n",
    "refine_combined_test_case(html_folder, pom_file_path, conftest_path, raw_test_path, output_file_path, api_key, base_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing chunk 1/41 ---\n",
      "LLM call failed: Error code: 401 - {'detail': 'Invalid Credential'}\n",
      "No test code received for chunk 1.\n",
      "\n",
      "--- Processing chunk 2/41 ---\n",
      "LLM call failed: Error code: 401 - {'detail': 'Invalid Credential'}\n",
      "No test code received for chunk 2.\n",
      "\n",
      "--- Processing chunk 3/41 ---\n",
      "LLM call failed: Error code: 401 - {'detail': 'Invalid Credential'}\n",
      "No test code received for chunk 3.\n",
      "\n",
      "--- Processing chunk 4/41 ---\n",
      "LLM call failed: Error code: 401 - {'detail': 'Invalid Credential'}\n",
      "No test code received for chunk 4.\n",
      "\n",
      "--- Processing chunk 5/41 ---\n",
      "LLM call failed: Error code: 401 - {'detail': 'Invalid Credential'}\n",
      "No test code received for chunk 5.\n",
      "\n",
      "--- Processing chunk 6/41 ---\n",
      "LLM call failed: Error code: 401 - {'detail': 'Invalid Credential'}\n",
      "No test code received for chunk 6.\n",
      "\n",
      "--- Processing chunk 7/41 ---\n",
      "LLM call failed: Error code: 401 - {'detail': 'Invalid Credential'}\n",
      "No test code received for chunk 7.\n",
      "\n",
      "--- Processing chunk 8/41 ---\n",
      "LLM call failed: Error code: 401 - {'detail': 'Invalid Credential'}\n",
      "No test code received for chunk 8.\n",
      "\n",
      "--- Processing chunk 9/41 ---\n",
      "LLM call failed: Error code: 401 - {'detail': 'Invalid Credential'}\n",
      "No test code received for chunk 9.\n",
      "\n",
      "--- Processing chunk 10/41 ---\n",
      "LLM call failed: Error code: 401 - {'detail': 'Invalid Credential'}\n",
      "No test code received for chunk 10.\n",
      "\n",
      "--- Processing chunk 11/41 ---\n",
      "LLM call failed: Error code: 401 - {'detail': 'Invalid Credential'}\n",
      "No test code received for chunk 11.\n",
      "\n",
      "--- Processing chunk 12/41 ---\n",
      "LLM call failed: Error code: 401 - {'detail': 'Invalid Credential'}\n",
      "No test code received for chunk 12.\n",
      "\n",
      "--- Processing chunk 13/41 ---\n",
      "LLM call failed: Error code: 401 - {'detail': 'Invalid Credential'}\n",
      "No test code received for chunk 13.\n",
      "\n",
      "--- Processing chunk 14/41 ---\n",
      "LLM call failed: Error code: 401 - {'detail': 'Invalid Credential'}\n",
      "No test code received for chunk 14.\n",
      "\n",
      "--- Processing chunk 15/41 ---\n",
      "LLM call failed: Error code: 401 - {'detail': 'Invalid Credential'}\n",
      "No test code received for chunk 15.\n",
      "\n",
      "--- Processing chunk 16/41 ---\n",
      "LLM call failed: Error code: 401 - {'detail': 'Invalid Credential'}\n",
      "No test code received for chunk 16.\n",
      "\n",
      "--- Processing chunk 17/41 ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 110\u001b[0m\n\u001b[0;32m    107\u001b[0m base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://stg-logiai-service.np.logitech.io/openai/v1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;66;03m# Call to generate the final test code\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m \u001b[43mgenerate_single_test_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhtml_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpom_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconftest_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_test_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 88\u001b[0m, in \u001b[0;36mgenerate_single_test_file\u001b[1;34m(html_folder, pom_file_path, conftest_path, raw_test_path, output_file_path, api_key, base_url)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(html_chunks_split):\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Processing chunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(html_chunks_split)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 88\u001b[0m     test_code \u001b[38;5;241m=\u001b[39m \u001b[43msend_to_llm_single_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpom_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconftest_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m test_code:\n\u001b[0;32m     90\u001b[0m         combined_test_code \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# === Test from chunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ===\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtest_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[24], line 52\u001b[0m, in \u001b[0;36msend_to_llm_single_chunk\u001b[1;34m(html_chunk, pom_code, conftest_code, api_key, base_url)\u001b[0m\n\u001b[0;32m     42\u001b[0m prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are an expert in Selenium and Pytest.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerate a Python test function using pytest and the provided conftest fixture and Page Object Model (POM).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconftest.py:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mconftest_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4096\u001b[39;49m\n\u001b[0;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m extract_code(completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\openai\\_utils\\_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\openai\\resources\\chat\\completions\\completions.py:925\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    922\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    923\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    924\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    936\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    937\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\openai\\_base_client.py:1239\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1226\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1227\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1235\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1236\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1237\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[1;32m-> 1239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\openai\\_base_client.py:969\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m    967\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 969\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    970\u001b[0m         request,\n\u001b[0;32m    971\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    972\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    973\u001b[0m     )\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    975\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\httpx\\_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\httpx\\_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\httpx\\_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    977\u001b[0m     hook(request)\n\u001b[1;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\httpx\\_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1011\u001b[0m     )\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\httpx\\_transports\\default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    248\u001b[0m )\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    259\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\httpcore\\_sync\\http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\httpcore\\_sync\\http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    100\u001b[0m     (\n\u001b[0;32m    101\u001b[0m         http_version,\n\u001b[0;32m    102\u001b[0m         status,\n\u001b[0;32m    103\u001b[0m         reason_phrase,\n\u001b[0;32m    104\u001b[0m         headers,\n\u001b[0;32m    105\u001b[0m         trailing_data,\n\u001b[1;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\httpcore\\_sync\\http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\ssl.py:1259\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1256\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1257\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1258\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\ssl.py:1132\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# === Utility Functions ===\n",
    "\n",
    "def read_files_from_folder(folder_path):\n",
    "    contents = []\n",
    "    try:\n",
    "        for filename in sorted(os.listdir(folder_path)):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    contents.append(file.read())\n",
    "        return contents\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading files from folder: {e}\")\n",
    "        return []\n",
    "\n",
    "def read_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def extract_code(response_text):\n",
    "    if \"```python\" in response_text:\n",
    "        return response_text.split(\"```python\")[1].split(\"```\")[0].strip()\n",
    "    return response_text.strip()\n",
    "\n",
    "def chunk_text(text, max_chars=10000):  # Split into 10,000 characters per chunk\n",
    "    \"\"\"\n",
    "    Split text into substrings of up to max_chars.\n",
    "    \"\"\"\n",
    "    return [text[i:i + max_chars] for i in range(0, len(text), max_chars)]\n",
    "\n",
    "def send_to_llm_single_chunk(html_chunk, pom_code, conftest_code, api_key, base_url):\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI(api_key=api_key, base_url=base_url)\n",
    "\n",
    "    prompt = (\n",
    "        \"You are an expert in Selenium and Pytest.\\n\"\n",
    "        \"Generate a Python test function using pytest and the provided conftest fixture and Page Object Model (POM).\\n\"\n",
    "        \"Use correct imports.\\n\\n\"\n",
    "        f\"HTML Snippet:\\n{html_chunk}\\n\\n\"\n",
    "        f\"POM Code:\\n{pom_code}\\n\\n\"\n",
    "        f\"conftest.py:\\n{conftest_code}\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=4096\n",
    "        )\n",
    "        return extract_code(completion.choices[0].message.content.strip())\n",
    "    except Exception as e:\n",
    "        print(f\"LLM call failed: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def save_combined_test(output_file_path, test_code):\n",
    "    try:\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(test_code)\n",
    "        print(f\"Final test file saved at: {output_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving final test file: {e}\")\n",
    "\n",
    "# === Main Function ===\n",
    "\n",
    "def generate_single_test_file(html_folder, pom_file_path, conftest_path, raw_test_path, output_file_path, api_key, base_url):\n",
    "    # Read HTML chunks\n",
    "    html_chunks = read_files_from_folder(html_folder)\n",
    "    html_combined = \"\\n\\n\".join(html_chunks)\n",
    "    # Read POM and conftest\n",
    "    pom_code = read_file(pom_file_path)\n",
    "    conftest_code = read_file(conftest_path)\n",
    "\n",
    "    # Chunk the combined HTML\n",
    "    html_chunks_split = chunk_text(html_combined, max_chars=10000)\n",
    "\n",
    "    combined_test_code = \"\"\n",
    "\n",
    "    # Process each chunk and generate test code\n",
    "    for i, chunk in enumerate(html_chunks_split):\n",
    "        print(f\"\\n--- Processing chunk {i+1}/{len(html_chunks_split)} ---\")\n",
    "        test_code = send_to_llm_single_chunk(chunk, pom_code, conftest_code, api_key, base_url)\n",
    "        if test_code:\n",
    "            combined_test_code += f\"# === Test from chunk {i+1} ===\\n{test_code}\\n\\n\"\n",
    "        else:\n",
    "            print(f\"No test code received for chunk {i+1}.\")\n",
    "\n",
    "    if combined_test_code:\n",
    "        save_combined_test(output_file_path, combined_test_code)\n",
    "    else:\n",
    "        print(\"No test code generated.\")\n",
    "\n",
    "# === Update these with correct paths ===\n",
    "\n",
    "html_folder = r\"C:\\genai\\ai_for_automation\\chunks_for_testing\"\n",
    "pom_file_path = r\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\page_objects\\page_objest.py\"\n",
    "conftest_path = r\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\configurations\\configurations\\conftest.py\"\n",
    "raw_test_path = r\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\test_cases\\test_final_combined.py\"\n",
    "output_file_path = r\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\test_cases\\test_final_cleaned.py\"\n",
    "api_key = access_token  # Insert your API key\n",
    "base_url = \"https://stg-logiai-service.np.logitech.io/openai/v1\"\n",
    "\n",
    "# Call to generate the final test code\n",
    "generate_single_test_file(html_folder, pom_file_path, conftest_path, raw_test_path, output_file_path, api_key, base_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Optimized code saved to: C:\\genai\\ai_for_automation\\selenium_pytest_project\\test_cases\\test_case.py\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "def read_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error reading file {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def extract_code(response_text):\n",
    "    if \"```python\" in response_text:\n",
    "        return response_text.split(\"```python\")[1].split(\"```\")[0].strip()\n",
    "    return response_text.strip()\n",
    "\n",
    "def optimize_code_with_llm(code, api_key, base_url):\n",
    "    client = openai.OpenAI(api_key=api_key, base_url=base_url)\n",
    "\n",
    "    prompt = (\n",
    "        \"You are a senior Python engineer.\\n\"\n",
    "        \"Optimize the following code by:\\n\"\n",
    "        \"- Reducing redundancy\\n\"\n",
    "        \"- Refactoring repeated patterns\\n\"\n",
    "        \"- Improving readability and structure\\n\"\n",
    "        \"- Keeping functionality exactly the same\\n\\n\"\n",
    "        f\"```python\\n{code}\\n```\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=2048\n",
    "        )\n",
    "        return extract_code(response.choices[0].message.content.strip())\n",
    "    except Exception as e:\n",
    "        print(f\" LLM optimization failed: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def write_file(file_path, content):\n",
    "    try:\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "        print(f\" Optimized code saved to: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error writing file: {e}\")\n",
    "\n",
    "# === MAIN RUN ===\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = r\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\test_cases\\test_final_combined.py\"\n",
    "    output_file = r\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\test_cases\\test_case.py\"\n",
    "    api_key = access_token  # Replace with actual token or use env var\n",
    "    base_url = \"https://stg-logiai-service.np.logitech.io/openai/v1\"\n",
    "\n",
    "    code = read_file(input_file)\n",
    "    if code:\n",
    "        optimized = optimize_code_with_llm(code, api_key, base_url)\n",
    "        if optimized:\n",
    "            write_file(output_file, optimized)\n",
    "        else:\n",
    "            print(\" No optimized code returned.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📤 Sending test cases + context to LLM...\n",
      "✅ Optimized test cases saved to: C:\\genai\\ai_for_automation\\selenium_pytest_project\\test_cases\\test_case.py\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# === File Handling Helpers ===\n",
    "\n",
    "def read_file(path):\n",
    "    try:\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    except Exception as e:\n",
    "        print(f\" Error reading {path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def write_file(path, content):\n",
    "    try:\n",
    "        with open(path, 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "        print(f\" Optimized test cases saved to: {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error writing to {path}: {e}\")\n",
    "\n",
    "# === Extract Python Code From Markdown ===\n",
    "\n",
    "def extract_code(response_text):\n",
    "    if \"```python\" in response_text:\n",
    "        return response_text.split(\"```python\")[1].split(\"```\")[0].strip()\n",
    "    return response_text.strip()\n",
    "\n",
    "# === LLM Optimization Call ===\n",
    "\n",
    "def optimize_test_code(test_code, pom_code, conftest_code, api_key, base_url):\n",
    "    client = openai.OpenAI(api_key=api_key, base_url=base_url)\n",
    "\n",
    "    prompt = (\n",
    "        \"You are a senior Python QA engineer using Selenium + Pytest.\\n\"\n",
    "        \"Here is the test case file I generated. Optimize it by:\\n\"\n",
    "        \"- Refactoring duplicate or verbose code\\n\"\n",
    "        \"- Using helper functions from POM\\n\"\n",
    "        \"- Utilizing fixtures from conftest.py\\n\"\n",
    "        \"- Maintaining the same behavior and logic\\n\\n\"\n",
    "        f\"--- conftest.py ---\\n{conftest_code}\\n\\n\"\n",
    "        f\"--- POM ---\\n{pom_code}\\n\\n\"\n",
    "        f\"--- Test Cases ---\\n```python\\n{test_code}\\n```\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=2048,\n",
    "            temperature=0.3,\n",
    "        )\n",
    "        return extract_code(response.choices[0].message.content.strip())\n",
    "    except Exception as e:\n",
    "        print(f\" LLM request failed: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# === Main Runner ===\n",
    "\n",
    "def optimize_tests(test_file, pom_file, conftest_file, output_file, api_key, base_url):\n",
    "    test_code = read_file(test_file)\n",
    "    pom_code = read_file(pom_file)\n",
    "    conftest_code = read_file(conftest_file)\n",
    "\n",
    "    if not test_code:\n",
    "        print(\" Test case file is empty.\")\n",
    "        return\n",
    "\n",
    "    print(\"📤 Sending test cases + context to LLM...\")\n",
    "    optimized = optimize_test_code(test_code, pom_code, conftest_code, api_key, base_url)\n",
    "\n",
    "    if optimized:\n",
    "        write_file(output_file, optimized)\n",
    "    else:\n",
    "        print(\" No optimized code returned.\")\n",
    "\n",
    "# === Example Execution ===\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    optimize_tests(\n",
    "        test_file=r\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\test_cases\\test_final_combined.py\",\n",
    "        pom_file=r\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\page_objects\\page_objest.py\",\n",
    "        conftest_file=r\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\configurations\\configurations\\conftest.py\",\n",
    "        output_file=r\"C:\\genai\\ai_for_automation\\selenium_pytest_project\\test_cases\\test_case.py\",\n",
    "        api_key=access_token,\n",
    "        base_url=\"https://stg-logiai-service.np.logitech.io/openai/v1\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
